# Spark-Kafka-example
A simple example of using spark and kafka and push to elasticsearch


## مقدمه
تصور کنید که با یک وب سرور nginx روبرو هستین که روزانه هزاران و یا حتی میلیونی کاربر دارد و شما میخواد 4 نیازمندی زیر را پوشش دهید:

1- اگر کاربری در هر 20 ثانیه بیشتر از 10 ریکوست زد، سیستم اطلاع رسانی کند

2- اگر تعداد نتیجه 4xx ریکوئست های هر هاست بیشتر از 15 بار در دقیقه بود، سیستم اطلاع رسانی کند.

3- به ازای هر کشور تعداد ریکوئست های موفق را محاسبه کند.

4- به ازای هر هاست میانگین زمان پاسخ دهی ریکوئست را محاسبه کند.

5- داده های خام را به صورت دائمی ذخیره کند

نمونه لاگ شبیه سازی شده وب سرور:
{'server': 's_v3', 'client_ip': '154.85.126.16', 'method': 'PUT', 'status': '201',
'request_time': '0.28', 'host': 'api_38.digikala.com', 'country': 'US', '@timestamp':
'1659509511.865323'}

## معماری
فکر کردن به مسئله و ارائه راهکار میتواند خیلی متنوع و وابسته به نیازمندی های هر سازمان و منابع باشد.
اگر فقط نیازمندی های مطرح شده را درنظر بگیریم، راهکار پیشنهادی بهتر است شرایط زیر را داشته باشد:
- در هیچ شرایطی داده از دست نرود.
- سامانه قابل اعتماد باشد و تقریبا در هیچ شرایطی متوقف نشود و در دسترس باشد
- single point of failure نداشته باشد.
- داده ها باید به صورت آنی پردازش شوند (با توجه به نیازمندی 1 و 2)
- با توجه به حجم داده ورودی، ظرفیت مناست ذخیره سازی فرآهم شود



## راهکار
![diagram-min](https://github.com/aliSadegh/Spark-Kafka-example/assets/24531562/307d453b-cef1-400c-8617-c415cdf8b775)
معماری و راهکار پیشنهادی استفاده از ابزارهای زیر است:
- Kafka: